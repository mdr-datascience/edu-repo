{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Malware Detection in Network Traffic\n",
    "\n",
    "## Random Forest Classification\n",
    "\n",
    "Run the quickstart_ml_eda.ipynb to obtain the preprocessed data for this analysis.\n",
    "\n",
    "This tutorial is based on the following work:\n",
    "\n",
    "https://github.com/aruberts/tutorials/blob/main/pyspark/spark_feature_engineering.ipynb\n",
    "\n",
    "https://www.youtube.com/watch?v=TlXqsL4ysB0&t=1322s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyspark==3.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.appName(\"iot\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load preprocessed Parquet data\n",
    "\n",
    "Load data preprocessed in the previous tutorial and while loading create a new variable \"is_bad\" with the numerical value 1 for malicious traffic and 0 for benign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe = spark.read.parquet(\"/content/drive/MyDrive/NetworkMalwareData/processed.pq\").withColumn(\n",
    "    \"is_bad\", F.when(F.col(\"label\") != \"Benign\", 1).otherwise(0)\n",
    ")\n",
    "df_fe.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Select numerical and categorical features for analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = [\n",
    "    \"duration\",\n",
    "    \"orig_bytes\",\n",
    "    \"resp_bytes\",\n",
    "    \"orig_pkts\",\n",
    "    \"orig_ip_bytes\",\n",
    "    \"resp_pkts\",\n",
    "    \"resp_ip_bytes\",\n",
    "]\n",
    "categorical_features = [\"proto\", \"service\", \"conn_state\", \"history\"]\n",
    "categorical_features_indexed = [c + \"_index\" for c in categorical_features]\n",
    "\n",
    "input_features = numerical_features + categorical_features_indexed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rare categories\n",
    "Count unique entries for each categorical variable and delete rare categories (less than 100 unique entries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe.select([F.count_distinct(c) for c in categorical_features]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_valid_values = {}\n",
    "\n",
    "for c in categorical_features:\n",
    "    # Find frequent values\n",
    "    categorical_valid_values[c] = (\n",
    "        df_fe.groupby(c)\n",
    "        .count()\n",
    "        .filter(F.col(\"count\") > 100)\n",
    "        .select(c)\n",
    "        .toPandas()\n",
    "        .values.ravel()\n",
    "    )\n",
    "\n",
    "    df_fe = df_fe.withColumn(\n",
    "        c,\n",
    "        F.when(F.col(c).isin(list(categorical_valid_values[c])), F.col(c)).otherwise(\n",
    "            F.lit(\"Other\").alias(c)\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe.select([F.count_distinct(c) for c in categorical_features]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split\n",
    "The Train-test split needs to be done using the source IP address, otherwise we risk leaking data. First we count and order the malicious IP addresses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe.groupby(\"source_ip\").agg(F.sum(F.col(\"is_bad\")).alias(\"bad_sum\")).orderBy(\"bad_sum\", ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can select 80% of the non-malicious IP addresses for the training set and the rest for the test set by creating a new variable is_train. Then we can select one of the top malicious IP addresses for the training data and the other IP address for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training non-malicious IPs (80%)\n",
    "train_ips = (\n",
    "    df_fe.where(\n",
    "        ~F.col(\"source_ip\").isin([\"192.168.100.103\", \"192.168.2.5\", \"192.168.2.1\"])\n",
    "    )\n",
    "    .select(F.col(\"source_ip\"), F.lit(1).alias(\"is_train\"))\n",
    "    .dropDuplicates()\n",
    "    .sample(0.8)\n",
    ")\n",
    "\n",
    "\n",
    "df_fe = df_fe.join(train_ips, \"source_ip\", \"left\")\n",
    "\n",
    "# Add 1 malicious IP to training and testing data\n",
    "df_train = df_fe.where((F.col(\"is_train\") == 1) | (F.col(\"source_ip\") == \"192.168.100.103\"))\n",
    "df_test = df_fe.where((F.col(\"is_train\") != 1) | (F.col(\"source_ip\") == \"192.168.2.5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pipeline for machine learning: one-hot encode categorical features, assemble features in a single vector, scale features, run random forest classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = StringIndexer(inputCols=categorical_features, outputCols=categorical_features_indexed, handleInvalid='skip')\n",
    "va = VectorAssembler(inputCols=input_features, outputCol=\"features\", handleInvalid='skip' )\n",
    "ss = StandardScaler(inputCol=\"features\", outputCol=\"features_scaled\")\n",
    "rf = RandomForestClassifier(featuresCol=\"features_scaled\", labelCol=\"is_bad\", numTrees=100)\n",
    "\n",
    "pipeline = Pipeline(stages=[ind, va, ss, rf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit pipeline to training data and transform using test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = pipeline.fit(df_train)\n",
    "test_preds = pipeline.transform(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print classification metrics to better understand results (e.g. ROC/PR area under the curve)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "roc = BinaryClassificationEvaluator(labelCol=\"is_bad\", metricName=\"areaUnderROC\")\n",
    "print(\"ROC AUC\", roc.evaluate(test_preds))\n",
    "\n",
    "pr = BinaryClassificationEvaluator(labelCol=\"is_bad\", metricName=\"areaUnderPR\")\n",
    "print(\"PR AUC\", pr.evaluate(test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Pandas dataframe of importance metric for each feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"importance\": list(pipeline.stages[-1].featureImportances),\n",
    "        \"feature\": pipeline.stages[-3].getInputCols(),\n",
    "    }\n",
    ").sort_values(\"importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save pipeline (either only random forest classifier or full pipeline):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.stages[-1].write().overwrite().save(\"rf_basic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.write().overwrite().save(\"pipeline_basic\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
