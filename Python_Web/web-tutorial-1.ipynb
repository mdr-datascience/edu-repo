{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1\n",
    "\n",
    "In this tutorial we are going to practice retrieving data from the web using Python.\n",
    "\n",
    "Let's start by using urllib to read data from web pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<!DOCTYPE html>\\n<html lang=\"en\">\\n    <head>\\n        <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\\n        <title>Scraping Sandbox</title>\\n        <link href=\"./css/bootstrap.min.css\" rel=\"stylesheet\">\\n        <link href=\"./css/main.css\" rel=\"stylesheet\">\\n    </head>\\n    <body>\\n        <div class=\"container\">\\n            <div class=\"row\">\\n                <div class=\"col-md-1\"></div>\\n                <div class=\"col-md-10 well\">\\n                    <img class=\"logo\" src=\"img/zyte.png\" width=\"200px\">\\n                    <h1 class=\"text-right\">Web Scraping Sandbox</h1>\\n                </div>\\n            </div>\\n\\n            <div class=\"row\">\\n                <div class=\"col-md-1\"></div>\\n                <div class=\"col-md-10\">\\n                    <h2>Books</h2>\\n                    <p>A <a href=\"http://books.toscrape.com\">fictional bookstore</a> that desperately wants to be scraped. It\\'s a safe place for beginners learning web scraping and for developers validating their scraping technologies as well. Available at: <a href=\"http://books.toscrape.com\">books.toscrape.com</a></p>\\n                    <div class=\"col-md-6\">\\n                        <a href=\"http://books.toscrape.com\"><img src=\"./img/books.png\" class=\"img-thumbnail\"></a>\\n                    </div>\\n                    <div class=\"col-md-6\">\\n                        <table class=\"table table-hover\">\\n                            <tr><th colspan=\"2\">Details</th></tr>\\n                            <tr><td>Amount of items </td><td>1000</td></tr>\\n                            <tr><td>Pagination </td><td>&#10004;</td></tr>\\n                            <tr><td>Items per page </td><td>max 20</td></tr>\\n                            <tr><td>Requires JavaScript </td><td>&#10008;</td></tr>\\n                        </table>\\n                    </div>\\n                </div>\\n            </div>\\n\\n            <div class=\"row\">\\n                <div class=\"col-md-1\"></div>\\n                <div class=\"col-md-10\">\\n                    <h2>Quotes</h2>\\n                    <p><a href=\"http://quotes.toscrape.com/\">A website</a> that lists quotes from famous people. It has many endpoints showing the quotes in many different ways, each of them including new scraping challenges for you, as described below.</p>\\n                    <div class=\"col-md-6\">\\n                        <a href=\"http://quotes.toscrape.com\"><img src=\"./img/quotes.png\" class=\"img-thumbnail\"></a>\\n                    </div>\\n                    <div class=\"col-md-6\">\\n                        <table class=\"table table-hover\">\\n                            <tr><th colspan=\"2\">Endpoints</th></tr>\\n                            <tr><td><a href=\"http://quotes.toscrape.com/\">Default</a></td><td>Microdata and pagination</td></tr>\\n                            <tr><td><a href=\"http://quotes.toscrape.com/scroll\">Scroll</a> </td><td>infinite scrolling pagination</td></tr>\\n                            <tr><td><a href=\"http://quotes.toscrape.com/js\">JavaScript</a> </td><td>JavaScript generated content</td></tr>\\n                            <tr><td><a href=\"http://quotes.toscrape.com/js-delayed\">Delayed</a> </td><td>Same as JavaScript but with a delay (?delay=10000)</td></tr>\\n                            <tr><td><a href=\"http://quotes.toscrape.com/tableful\">Tableful</a> </td><td>a table based messed-up layout</td></tr>\\n                            <tr><td><a href=\"http://quotes.toscrape.com/login\">Login</a> </td><td>login with CSRF token (any user/passwd works)</td></tr>\\n                            <tr><td><a href=\"http://quotes.toscrape.com/search.aspx\">ViewState</a> </td><td>an AJAX based filter form with ViewStates</td></tr>\\n                            <tr><td><a href=\"http://quotes.toscrape.com/random\">Random</a> </td><td>a single random quote</td></tr>\\n                        </table>\\n                    </div>\\n                </div>\\n            </div>\\n        </div>\\n    </body>\\n</html>\\n'\n"
     ]
    }
   ],
   "source": [
    "# Import urllib request module and read the entire content of python.org\n",
    "import urllib.request \n",
    "\n",
    "request_url = urllib.request.urlopen('https://toscrape.com/') \n",
    "print(request_url.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 3 lines of code the content of python.org was retrieved and printed but it doesn't look good. The next lines of code again read the same page content but print the content into a more readable format. .decode() converts information from byte arrays into strings and strip() gets rid of any leading, and trailing whitespaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n",
      "<title>Scraping Sandbox</title>\n",
      "<link href=\"./css/bootstrap.min.css\" rel=\"stylesheet\">\n",
      "<link href=\"./css/main.css\" rel=\"stylesheet\">\n",
      "</head>\n",
      "<body>\n",
      "<div class=\"container\">\n",
      "<div class=\"row\">\n",
      "<div class=\"col-md-1\"></div>\n",
      "<div class=\"col-md-10 well\">\n",
      "<img class=\"logo\" src=\"img/zyte.png\" width=\"200px\">\n",
      "<h1 class=\"text-right\">Web Scraping Sandbox</h1>\n",
      "</div>\n",
      "</div>\n",
      "\n",
      "<div class=\"row\">\n",
      "<div class=\"col-md-1\"></div>\n",
      "<div class=\"col-md-10\">\n",
      "<h2>Books</h2>\n",
      "<p>A <a href=\"http://books.toscrape.com\">fictional bookstore</a> that desperately wants to be scraped. It's a safe place for beginners learning web scraping and for developers validating their scraping technologies as well. Available at: <a href=\"http://books.toscrape.com\">books.toscrape.com</a></p>\n",
      "<div class=\"col-md-6\">\n",
      "<a href=\"http://books.toscrape.com\"><img src=\"./img/books.png\" class=\"img-thumbnail\"></a>\n",
      "</div>\n",
      "<div class=\"col-md-6\">\n",
      "<table class=\"table table-hover\">\n",
      "<tr><th colspan=\"2\">Details</th></tr>\n",
      "<tr><td>Amount of items </td><td>1000</td></tr>\n",
      "<tr><td>Pagination </td><td>&#10004;</td></tr>\n",
      "<tr><td>Items per page </td><td>max 20</td></tr>\n",
      "<tr><td>Requires JavaScript </td><td>&#10008;</td></tr>\n",
      "</table>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "\n",
      "<div class=\"row\">\n",
      "<div class=\"col-md-1\"></div>\n",
      "<div class=\"col-md-10\">\n",
      "<h2>Quotes</h2>\n",
      "<p><a href=\"http://quotes.toscrape.com/\">A website</a> that lists quotes from famous people. It has many endpoints showing the quotes in many different ways, each of them including new scraping challenges for you, as described below.</p>\n",
      "<div class=\"col-md-6\">\n",
      "<a href=\"http://quotes.toscrape.com\"><img src=\"./img/quotes.png\" class=\"img-thumbnail\"></a>\n",
      "</div>\n",
      "<div class=\"col-md-6\">\n",
      "<table class=\"table table-hover\">\n",
      "<tr><th colspan=\"2\">Endpoints</th></tr>\n",
      "<tr><td><a href=\"http://quotes.toscrape.com/\">Default</a></td><td>Microdata and pagination</td></tr>\n",
      "<tr><td><a href=\"http://quotes.toscrape.com/scroll\">Scroll</a> </td><td>infinite scrolling pagination</td></tr>\n",
      "<tr><td><a href=\"http://quotes.toscrape.com/js\">JavaScript</a> </td><td>JavaScript generated content</td></tr>\n",
      "<tr><td><a href=\"http://quotes.toscrape.com/js-delayed\">Delayed</a> </td><td>Same as JavaScript but with a delay (?delay=10000)</td></tr>\n",
      "<tr><td><a href=\"http://quotes.toscrape.com/tableful\">Tableful</a> </td><td>a table based messed-up layout</td></tr>\n",
      "<tr><td><a href=\"http://quotes.toscrape.com/login\">Login</a> </td><td>login with CSRF token (any user/passwd works)</td></tr>\n",
      "<tr><td><a href=\"http://quotes.toscrape.com/search.aspx\">ViewState</a> </td><td>an AJAX based filter form with ViewStates</td></tr>\n",
      "<tr><td><a href=\"http://quotes.toscrape.com/random\">Random</a> </td><td>a single random quote</td></tr>\n",
      "</table>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "request_url = urllib.request.urlopen('https://toscrape.com/') \n",
    "for line in request_url:\n",
    "    print(line.decode().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**TO DO:** Try using the same lines of code to read the following web page: https://data.pr4e.org/romeo.txt\n",
    "\n",
    "Open the webpage first in your browser to see how it looks and then use Python code to retrieve all its content into your Jupyter notebook. It should look something like this:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But soft what light through yonder window breaks\n",
      "It is the east and Juliet is the sun\n",
      "Arise fair sun and kill the envious moon\n",
      "Who is already sick and pale with grief\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**TO DO:** Retrieve content from other HTML pages, such as Wikipedia.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we are going to explore how we can read data from the web that is saved in the XML format. To do this, we are going to use a Python module called *xml* and explore some of its basic functionality for parsing XML data.\n",
    "\n",
    "Start by opening the following page using your browser: 'https://www.w3schools.com/xml/note.xml'.\n",
    "\n",
    "Now let's retrieve its XML content using Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xml is a Python module for retrieving and parsing xml data\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# requests is a module for http requests\n",
    "import requests \n",
    "\n",
    "# This is the URL we want to retrieve data from\n",
    "url = 'https://www.w3schools.com/xml/note.xml'\n",
    "  \n",
    "# We can use requests to request the data from the URL via the http protocol\n",
    "resp = requests.get(url) \n",
    "\n",
    "# We can save the data in a local xml file\n",
    "file_name = 'xmldata.xml'  \n",
    "with open(file_name, 'wb') as f:\n",
    "    f.write(resp.content) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the saved xml file to see its content.\n",
    "\n",
    "Now that we have an xml file saved in our directory we can read it (parse it) to extract useful information from this file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "note\n"
     ]
    }
   ],
   "source": [
    "# Use xml ET functionality to create a tree object with all the xml structure\n",
    "tree = ET.parse(file_name) \n",
    "  \n",
    "# Get root element (the first element of the xml structure)\n",
    "root = tree.getroot() \n",
    "  \n",
    "# Print the tag of root (first element of xml structure)\n",
    "print(root.tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To print all the tags and attributes you can do something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to {}\n",
      "from {}\n",
      "heading {}\n",
      "body {}\n"
     ]
    }
   ],
   "source": [
    "for child in root:\n",
    "    print(child.tag, child.attrib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract the actual information from a tag, use the command text, such as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tove\n",
      "Jani\n",
      "Reminder\n",
      "Don't forget me this weekend!\n"
     ]
    }
   ],
   "source": [
    "print(root[0].text)\n",
    "print(root[1].text)\n",
    "print(root[2].text)\n",
    "print(root[3].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tove\n",
      "Jani\n",
      "Reminder\n",
      "Don't forget me this weekend!\n"
     ]
    }
   ],
   "source": [
    "print(root.find('to').text)\n",
    "print(root.find('from').text)\n",
    "print(root.find('heading').text)\n",
    "print(root.find('body').text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**TO DO:** To finish, download the xml file called countries_data.xml (from Canvas) and explore parsing this xml file with Python. For more information, see here: https://docs.python.org/3/library/xml.etree.elementtree.html#module-xml.etree.ElementTree</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use xml ET functionality to create a tree object with all the xml structure\n",
    "# Your code here\n",
    "  \n",
    "# Get root element (the first element of the xml structure)\n",
    "# Your code here\n",
    "  \n",
    "# Print the tag of root (first element of xml structure)\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all tags and attributes (see above code for example)\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does the following lines of code return?\n",
    "print(root[0][1].text)\n",
    "print(root[1][0].text)\n",
    "print(root[1][1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the following code to return the neighbors of all countries\n",
    "for neighbor in root.iter('neighbor'):\n",
    "    print(neighbor.attrib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the following code to return the names and ranks of all countries\n",
    "for country in root.findall('country'):\n",
    "    rank = country.find('rank').text\n",
    "    name = country.get('name')\n",
    "    print(name, rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep exploring the data using your own code\n",
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
